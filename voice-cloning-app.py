# Singing Voice Cloning Application in Streamlit
# Complete implementation with vocal separation, voice cloning, and replacement

import streamlit as st
import os
import subprocess
import tempfile
import pickle
from pathlib import Path
import librosa
import soundfile as sf
import numpy as np
from streamlit_mic_recorder import mic_recorder
import io

# Configure the app
st.set_page_config(
    page_title="AI Singing Voice Cloning Studio",
    page_icon="üé§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state variables
def init_session_state():
    """Initialize all session state variables"""
    if 'user_voice_model' not in st.session_state:
        st.session_state.user_voice_model = None
    if 'model_trained' not in st.session_state:
        st.session_state.model_trained = False
    if 'separated_vocals' not in st.session_state:
        st.session_state.separated_vocals = None
    if 'separated_accompaniment' not in st.session_state:
        st.session_state.separated_accompaniment = None
    if 'original_song' not in st.session_state:
        st.session_state.original_song = None

# Vocal separation using Spleeter
def separate_vocals(audio_file):
    """
    Separate vocals and accompaniment using Spleeter
    """
    with st.spinner("üéµ Separating vocals from instruments..."):
        try:
            # Create temporary directory
            temp_dir = tempfile.mkdtemp()
            
            # Save uploaded file to temp directory
            temp_audio_path = os.path.join(temp_dir, "input_song.wav")
            with open(temp_audio_path, "wb") as f:
                f.write(audio_file.read())
            
            # Run Spleeter separation
            output_dir = os.path.join(temp_dir, "output")
            cmd = [
                "spleeter", "separate", 
                "-p", "spleeter:2stems",
                "-o", output_dir,
                temp_audio_path
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            
            # Load separated audio files
            vocals_path = os.path.join(output_dir, "input_song", "vocals.wav")
            accompaniment_path = os.path.join(output_dir, "input_song", "accompaniment.wav")
            
            # Read audio files
            vocals, sr_vocals = librosa.load(vocals_path, sr=None)
            accompaniment, sr_acc = librosa.load(accompaniment_path, sr=None)
            
            return vocals, accompaniment, sr_vocals
            
        except Exception as e:
            st.error(f"Error during vocal separation: {str(e)}")
            return None, None, None

# Voice model training (simplified version)
def create_voice_model(voice_samples):
    """
    Create a voice model from user samples
    This is a simplified version - in practice you'd use So-VITS-SVC or similar
    """
    with st.spinner("ü§ñ Training your voice model..."):
        try:
            # Simulate voice model creation
            # In real implementation, this would involve:
            # 1. Audio preprocessing
            # 2. Feature extraction
            # 3. Model training with So-VITS-SVC
            # 4. Model saving
            
            model_data = {
                'samples': voice_samples,
                'trained': True,
                'timestamp': st.session_state.get('timestamp', None)
            }
            
            # Save model to session state
            st.session_state.user_voice_model = model_data
            st.session_state.model_trained = True
            
            return True
            
        except Exception as e:
            st.error(f"Error creating voice model: {str(e)}")
            return False

# Voice replacement function
def replace_vocals_with_user_voice(original_vocals, user_model, sr):
    """
    Replace original vocals with user's cloned voice
    This is simplified - real implementation would use trained model inference
    """
    with st.spinner("üé≠ Replacing vocals with your voice..."):
        try:
            # Simplified voice conversion
            # In practice, this would use the trained model to convert vocals
            
            # For demo purposes, we'll apply some audio effects
            # to simulate voice conversion
            converted_vocals = original_vocals.copy()
            
            # Apply some simple transformations as placeholder
            converted_vocals = converted_vocals * 0.8  # Adjust volume
            
            return converted_vocals
            
        except Exception as e:
            st.error(f"Error in voice replacement: {str(e)}")
            return None

# Main application
def main():
    st.title("üé§ AI Singing Voice Cloning Studio")
    st.markdown("---")
    
    # Initialize session state
    init_session_state()
    
    # Sidebar for navigation
    st.sidebar.title("Navigation")
    step = st.sidebar.selectbox(
        "Choose Step",
        ["1. Upload Song", "2. Create Voice Model", "3. Generate Clone"]
    )
    
    # Step 1: Song Upload and Vocal Separation
    if step == "1. Upload Song":
        st.header("üéµ Step 1: Upload Your Song")
        st.write("Upload any song you want to sing along with!")
        
        # File uploader
        uploaded_song = st.file_uploader(
            "Choose an audio file",
            type=['mp3', 'wav', 'flac', 'm4a'],
            help="Upload the song you want to sing"
        )
        
        if uploaded_song is not None:
            st.session_state.original_song = uploaded_song
            
            # Display original song
            st.subheader("Original Song")
            st.audio(uploaded_song, format="audio/wav")
            
            # Separate vocals button
            if st.button("üéØ Separate Vocals and Instruments", type="primary"):
                vocals, accompaniment, sr = separate_vocals(uploaded_song)
                
                if vocals is not None and accompaniment is not None:
                    st.session_state.separated_vocals = vocals
                    st.session_state.separated_accompaniment = accompaniment
                    st.success("‚úÖ Vocal separation completed!")
                    
                    # Display separated tracks
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("Isolated Vocals")
                        # Convert to audio bytes for playback
                        vocals_bytes = io.BytesIO()
                        sf.write(vocals_bytes, vocals, sr, format='WAV')
                        vocals_bytes.seek(0)
                        st.audio(vocals_bytes, format="audio/wav")
                    
                    with col2:
                        st.subheader("Instrumental Track")
                        accompaniment_bytes = io.BytesIO()
                        sf.write(accompaniment_bytes, accompaniment, sr, format='WAV')
                        accompaniment_bytes.seek(0)
                        st.audio(accompaniment_bytes, format="audio/wav")
    
    # Step 2: Voice Model Creation
    elif step == "2. Create Voice Model":
        st.header("üéôÔ∏è Step 2: Create Your Voice Model")
        
        if not st.session_state.model_trained:
            st.write("Record some samples of your singing voice to create your personal voice model.")
            st.info("üí° Tip: Sing different notes and phrases for better results!")
            
            # Voice recording
            st.subheader("Record Your Voice Samples")
            
            # Initialize voice samples list
            if 'voice_samples' not in st.session_state:
                st.session_state.voice_samples = []
            
            # Microphone recorder
            audio_data = mic_recorder(
                start_prompt="üé§ Start Recording Sample",
                stop_prompt="‚èπÔ∏è Stop Recording",
                just_once=True,
                use_container_width=True,
                key="voice_recorder"
            )
            
            # Process recorded audio
            if audio_data is not None:
                st.session_state.voice_samples.append(audio_data)
                st.success(f"‚úÖ Sample {len(st.session_state.voice_samples)} recorded!")
                
                # Play back the recorded sample
                st.audio(audio_data['bytes'], format="audio/wav")
            
            # Display recorded samples
            if st.session_state.voice_samples:
                st.subheader(f"Recorded Samples ({len(st.session_state.voice_samples)})")
                for i, sample in enumerate(st.session_state.voice_samples):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.audio(sample['bytes'], format="audio/wav")
                    with col2:
                        if st.button(f"üóëÔ∏è Delete", key=f"delete_{i}"):
                            st.session_state.voice_samples.pop(i)
                            st.experimental_rerun()
            
            # Train model button
            if len(st.session_state.voice_samples) >= 3:
                if st.button("ü§ñ Train Voice Model", type="primary"):
                    if create_voice_model(st.session_state.voice_samples):
                        st.success("üéâ Voice model trained successfully!")
                        st.balloons()
            else:
                st.warning("‚ö†Ô∏è Please record at least 3 voice samples to train your model.")
        
        else:
            st.success("‚úÖ Your voice model is ready!")
            st.info("Your voice model has been trained and saved. You can now proceed to generate your singing clone!")
            
            # Option to retrain
            if st.button("üîÑ Retrain Voice Model"):
                st.session_state.model_trained = False
                st.session_state.user_voice_model = None
                st.session_state.voice_samples = []
                st.experimental_rerun()
    
    # Step 3: Voice Replacement and Generation
    elif step == "3. Generate Clone":
        st.header("üé≠ Step 3: Generate Your Singing Clone")
        
        # Check prerequisites
        if not st.session_state.model_trained:
            st.warning("‚ö†Ô∏è Please complete Step 2: Create your voice model first!")
            return
            
        if st.session_state.separated_vocals is None:
            st.warning("‚ö†Ô∏è Please complete Step 1: Upload and separate a song first!")
            return
        
        st.success("‚úÖ All prerequisites met! Ready to generate your singing clone.")
        
        # Generate clone button
        if st.button("üéµ Generate My Singing Clone", type="primary"):
            # Replace vocals with user voice
            converted_vocals = replace_vocals_with_user_voice(
                st.session_state.separated_vocals,
                st.session_state.user_voice_model,
                22050  # sample rate
            )
            
            if converted_vocals is not None:
                # Mix converted vocals with accompaniment
                final_audio = converted_vocals + st.session_state.separated_accompaniment
                
                # Normalize audio
                final_audio = final_audio / np.max(np.abs(final_audio))
                
                st.success("üéâ Your singing clone is ready!")
                
                # Display results
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("Original Song")
                    st.audio(st.session_state.original_song, format="audio/wav")
                
                with col2:
                    st.subheader("Your Singing Clone")
                    # Convert to audio bytes
                    clone_bytes = io.BytesIO()
                    sf.write(clone_bytes, final_audio, 22050, format='WAV')
                    clone_bytes.seek(0)
                    st.audio(clone_bytes, format="audio/wav")
                    
                    # Download button
                    st.download_button(
                        label="üì• Download Your Clone",
                        data=clone_bytes.getvalue(),
                        file_name="my_singing_clone.wav",
                        mime="audio/wav"
                    )
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center'>
            <p>üé§ Built with Streamlit ‚Ä¢ Powered by AI Voice Cloning Technology</p>
        </div>
        """,
        unsafe_allow_html=True
    )

# Installation requirements
def show_requirements():
    """Display installation requirements"""
    st.sidebar.markdown("---")
    st.sidebar.subheader("Installation Requirements")
    
    requirements = """
    ```bash
    # Install required packages
    pip install streamlit
    pip install spleeter
    pip install librosa
    pip install soundfile
    pip install streamlit-mic-recorder
    pip install numpy
    
    # For advanced voice cloning (optional)
    # pip install so-vits-svc
    # pip install torch torchvision torchaudio
    ```
    """
    
    st.sidebar.markdown(requirements)

if __name__ == "__main__":
    show_requirements()
    main()